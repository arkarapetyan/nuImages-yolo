{"cells":[{"cell_type":"markdown","metadata":{"id":"LdQE83bRPAPG"},"source":["# Dataset Creation with nuImages devkit."]},{"cell_type":"markdown","metadata":{"id":"UX6iKl_6o21c"},"source":["### Mounting Google Drive (Optional, Requires lots of disk space)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OcZBuwGRQKW2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/MyDrive/nuImages-yolo"]},{"cell_type":"markdown","metadata":{"id":"bBEGtQ61PIZE"},"source":["## Downloading and Installing Dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1127817,"status":"ok","timestamp":1716571337144,"user":{"displayName":"Aren Karapetyan","userId":"12074025844959044397"},"user_tz":-240},"id":"P_FITOKEOJex","outputId":"087b44b8-8402-49e3-8743-d02c0ae3ab76"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-05-24 17:03:28--  https://d36yt3mvayqw5m.cloudfront.net/public/nuimages-v1.0/nuimages-v1.0-all-samples.tgz\n","Resolving d36yt3mvayqw5m.cloudfront.net (d36yt3mvayqw5m.cloudfront.net)... 108.156.78.96, 108.156.78.61, 108.156.78.205, ...\n","Connecting to d36yt3mvayqw5m.cloudfront.net (d36yt3mvayqw5m.cloudfront.net)|108.156.78.96|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 16381401772 (15G) [application/x-tar]\n","Saving to: ‘nuimages-v1.0-all-samples.tgz’\n","\n","nuimages-v1.0-all-s 100%[===================>]  15.26G  22.8MB/s    in 12m 47s \n","\n","2024-05-24 17:16:15 (20.4 MB/s) - ‘nuimages-v1.0-all-samples.tgz’ saved [16381401772/16381401772]\n","\n","--2024-05-24 17:21:14--  https://d36yt3mvayqw5m.cloudfront.net/public/nuimages-v1.0/nuimages-v1.0-all-metadata.tgz\n","Resolving d36yt3mvayqw5m.cloudfront.net (d36yt3mvayqw5m.cloudfront.net)... 108.156.78.205, 108.156.78.96, 108.156.78.61, ...\n","Connecting to d36yt3mvayqw5m.cloudfront.net (d36yt3mvayqw5m.cloudfront.net)|108.156.78.205|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 639386088 (610M) [application/x-tar]\n","Saving to: ‘nuimages-v1.0-all-metadata.tgz’\n","\n","nuimages-v1.0-all-m 100%[===================>] 609.77M  20.6MB/s    in 32s     \n","\n","2024-05-24 17:21:47 (19.0 MB/s) - ‘nuimages-v1.0-all-metadata.tgz’ saved [639386088/639386088]\n","\n"]}],"source":["%mkdir -p ./data/sets/nuimages  # Make the directory to store the nuImages dataset in.\n","\n","!wget https://d36yt3mvayqw5m.cloudfront.net/public/nuimages-v1.0/nuimages-v1.0-all-samples.tgz # Download samples.\n","\n","!tar -xf nuimages-v1.0-all-samples.tgz -C ./data/sets/nuimages  # Uncompress.\n","\n","!wget https://d36yt3mvayqw5m.cloudfront.net/public/nuimages-v1.0/nuimages-v1.0-all-metadata.tgz # Download metadata\n","\n","!tar -xf nuimages-v1.0-all-metadata.tgz -C ./data/sets/nuimages  # Uncompress."]},{"cell_type":"markdown","metadata":{"id":"HCNCymaLPMG0"},"source":["## Initialization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ti13KgoZPOcb"},"outputs":[],"source":["%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","import os\n","import json\n","import yaml\n","from shutil import copyfile"]},{"cell_type":"code","source":["root = './data/sets/nuimages/' # directory of the downloaded data\n","split = 'test' # the split of the dataset. Can be train/val/test\n","path = './datasets/nuImages' # the root directory of the created dataset"],"metadata":{"id":"ePF9Dlv381AK"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yIVgf0Tx5CRr"},"outputs":[],"source":["# load the tables\n","\n","tables = {'sample_data': None, 'object_ann': None, 'category': None}\n","for name in tables.keys():\n","  with open(os.path.join(root, f'v1.0-{split}', f'{name}.json')) as table_file:\n","    tables[name] = json.load(table_file)"]},{"cell_type":"markdown","source":["## Obtaining the classes"],"metadata":{"id":"xHXMfYDpJqFC"}},{"cell_type":"code","source":["class_indices = {}\n","classes = {}\n","c = 0"],"metadata":{"id":"7dNxT5C_etvs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_class(category_token):\n","  for category in tables['category']:\n","    if category['token'] == category_token:\n","      return category['name']\n","  raise KeyError()\n","  return None"],"metadata":{"id":"6ci9G-H17gJH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cat_count = len(tables['category'])\n","for i, category in enumerate(tables['category']):\n","  print(f'category: {i+1}/{cat_count}')\n","  class_indices[category['name']] = i\n","  classes[category['token']] = i"],"metadata":{"id":"lWzAl5tQewRr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Creating the samples."],"metadata":{"id":"BCdC3gzxJ2BR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"iyh9i12Wj7j9"},"outputs":[],"source":["samples = {}\n","start = 0\n","sample_count = 8000"]},{"cell_type":"code","source":["def get_filename(data_token):\n","  for sample in tables['sample_data']:\n","    if sample['token'] == data_token:\n","      return sample['filename']\n","  raise KeyError()\n","  return None\n","\n","\n","def get_class(category_token):\n","  for category in tables['category']:\n","    if category['token'] == category_token:\n","      return category['name']\n","  raise KeyError()\n","  return None\n","\n","\n","def relative_bbox(raw_bbox, size):\n","  x_center = round((raw_bbox[0] + raw_bbox[2]) / (2 * size[1]), 6)\n","  y_center = round((raw_bbox[1] + raw_bbox[3]) / (2 * size[0]), 6)\n","  width = round((raw_bbox[2] - raw_bbox[0]) / size[1], 6)\n","  height = round((raw_bbox[3] - raw_bbox[1]) / size[0], 6)\n","  if x_center > 1 or y_center > 1 or width < 0 or height < 0:\n","    raise ValueError() #debugging\n","  return [x_center, y_center, width, height]"],"metadata":{"id":"hmAeW30Ko5SE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create the dataset dictionary\n","\n","sample_data_list = list(filter(lambda s: s['is_key_frame'], tables['sample_data']))\n","for i, sample in enumerate(sample_data_list[start:start+sample_count]):\n","  print(f'sample {i+1}/{sample_count}', end='')\n","  if not sample['is_key_frame']:\n","    print('not a keyframe')\n","    continue\n","  else:\n","    print('')\n","  token = sample['token']\n","  objects = list(filter(lambda obj: obj['sample_data_token']==token, tables['object_ann']))\n","  labels = []\n","  for obj in objects:\n","    size = obj['mask']['size'] if obj.get('mask', None) else [900, 1600]\n","    bbox = relative_bbox(obj['bbox'], size)\n","    obj_class = classes[obj['category_token']]\n","    obj_label = [obj_class] + bbox\n","    obj_label = ' '.join([str(x) for x in obj_label])\n","    labels.append(obj_label)\n","  samples[token] = {}\n","  samples[token]['filename'] = sample['filename']\n","  samples[token]['label'] = '\\n'.join(labels)\n"],"metadata":{"id":"e4x3apKLe3qb"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GOlbXS7rC8qm"},"outputs":[],"source":["# save the samples to the files\n","for i, (token, sample) in enumerate(samples.items()):\n","  print(f'sample {i + 1}/{sample_count}')\n","  data_full_path = os.path.join(root, sample['filename'])\n","  data_new_path = os.path.join(path, 'images', split)\n","  if not os.path.exists(data_new_path):\n","    os.makedirs(data_new_path)\n","  copyfile(data_full_path, os.path.join(data_new_path, f'{token}.jpg'))\n","\n","  label_path = os.path.join(path, 'labels', split)\n","  if not os.path.exists(label_path):\n","    os.makedirs(label_path)\n","  with open(os.path.join(label_path, f'{token}.txt'), 'w') as label_file:\n","    label_file.write(sample['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LMKkkZ4J8LCH"},"outputs":[],"source":["!tar -czvf nuImages-val-2.tar.gz ./datasets/"]},{"cell_type":"code","source":["!rm -rf ./datasets"],"metadata":{"id":"A8PW5ffT2yuk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## YAML Creation"],"metadata":{"id":"yG_cC6V1ixwb"}},{"cell_type":"code","source":["# Run this if the previous processes were not executed in the current runtime.\n","os.makedirs(path)\n","path = './datasets/nuImages'"],"metadata":{"id":"oqadlYQFGNrE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def create_coco_yaml(class_dict, file_name):\n","    # Construct the categories list in COCO format\n","    categories = {idx: name for name, idx in class_dict.items()}\n","\n","    # Construct the final COCO dataset dictionary\n","    coco_dict = {\n","        'path': path,\n","        'train': 'images/train',\n","        'val': 'images/val',\n","        'names': categories\n","    }\n","\n","    # Write the COCO dictionary to a YAML file\n","    try:\n","        with open(file_name, 'w') as yaml_file:\n","            yaml.dump(coco_dict, yaml_file, default_flow_style=False)\n","        print(f\"COCO dataset YAML successfully written to {file_name}\")\n","    except Exception as e:\n","        print(f\"Error writing COCO dataset to YAML file: {e}\")"],"metadata":{"id":"JThCon4si1s1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["create_coco_yaml(class_indices, os.path.join(path, 'data.yaml'))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_mwnfUFYojzm","executionInfo":{"status":"ok","timestamp":1716059200517,"user_tz":-240,"elapsed":5,"user":{"displayName":"Aren Karapetyan","userId":"12074025844959044397"}},"outputId":"449c6180-aeaf-4119-adb6-e02ab05ec8d8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["COCO dataset YAML successfully written to /datasets/nuImages/data.yaml\n"]}]},{"cell_type":"code","source":["!tar -czvf nuImages-yaml.tar.gz ../datasets/"],"metadata":{"id":"S8sqJJBRrMK2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## The Test set"],"metadata":{"id":"JHhttLbdo3bp"}},{"cell_type":"code","source":["samples = {}\n","start = 0"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fUHcdUQhrBtp","executionInfo":{"status":"ok","timestamp":1716572141592,"user_tz":-240,"elapsed":4,"user":{"displayName":"Aren Karapetyan","userId":"12074025844959044397"}},"outputId":"351f125b-6cfd-4828-edf9-18c75bfc0ef2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["9752"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":[" # run this if training set procedure was not completed in the current runtime\n","\n"," def get_filename(data_token):\n","  for sample in tables['sample_data']:\n","    if sample['token'] == data_token:\n","      return sample['filename']\n","  raise KeyError()\n","  return None"],"metadata":{"id":"SBFGeXQefhUC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sample_data_list = list(filter(lambda s: s['is_key_frame'], tables['sample_data']))\n","for i, sample in enumerate(sample_data_list):\n","  print(f'sample {i+1}/{sample_count}', end='')\n","  if not sample['is_key_frame']:\n","    print('not a keyframe')\n","    continue\n","  else:\n","    print('')\n","  token = sample['token']\n","  samples[token] = {}\n","  samples[token]['filename'] = sample['filename']\n","  samples[token]['label'] = []\n","\n","\n","for i, (token, sample) in enumerate(samples.items()):\n","  print(f'sample {i + 1}/{sample_count}')\n","  data_full_path = os.path.join(root, sample['filename'])\n","  data_new_path = os.path.join(path, 'images', split)\n","  if not os.path.exists(data_new_path):\n","    os.makedirs(data_new_path)\n","  copyfile(data_full_path, os.path.join(data_new_path, f'{token}.jpg'))"],"metadata":{"id":"IQZ5HtlHo2z5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!tar -czvf nuImages-test.tar.gz ./datasets/"],"metadata":{"id":"xIK1m4NCrTL6"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"collapsed_sections":["UX6iKl_6o21c","bBEGtQ61PIZE","HCNCymaLPMG0","xHXMfYDpJqFC","BCdC3gzxJ2BR","yG_cC6V1ixwb","JHhttLbdo3bp"],"mount_file_id":"1kH4Cu4NLJEV-u1t8SRT2jyKXdPx5igzK","authorship_tag":"ABX9TyPbDkcLHBNu14U864K3l1SB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}